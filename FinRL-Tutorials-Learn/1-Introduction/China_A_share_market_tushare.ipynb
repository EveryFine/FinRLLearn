{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quantitative trading in China A stock market with FinRL",
   "id": "300777e805cc318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:01.517158Z",
     "start_time": "2024-11-10T12:40:59.149935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install stockstats\n",
    "!pip install tushare"
   ],
   "id": "e295d3fdfbc5ac38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stockstats in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (0.5.4)\r\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from stockstats) (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2024.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: tushare in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (1.4.13)\r\n",
      "Requirement already satisfied: pandas in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (2.2.3)\r\n",
      "Requirement already satisfied: requests in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (2.32.3)\r\n",
      "Requirement already satisfied: lxml in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (5.3.0)\r\n",
      "Requirement already satisfied: simplejson in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (3.19.3)\r\n",
      "Requirement already satisfied: bs4 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (0.0.2)\r\n",
      "Requirement already satisfied: websocket-client>=0.57.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (1.8.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from tushare) (4.66.6)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from bs4->tushare) (4.12.3)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas->tushare) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas->tushare) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas->tushare) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from pandas->tushare) (2024.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from requests->tushare) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from requests->tushare) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from requests->tushare) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from requests->tushare) (2024.8.30)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->tushare) (1.16.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from beautifulsoup4->bs4->tushare) (2.6)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:02.684368Z",
     "start_time": "2024-11-10T12:41:01.518700Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install TA-Lib",
   "id": "90b0634fb2455315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TA-Lib in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (0.4.32)\r\n",
      "Requirement already satisfied: numpy in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from TA-Lib) (1.26.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:03.873070Z",
     "start_time": "2024-11-10T12:41:02.685228Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install gym",
   "id": "6ace536eb59cb837",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (0.26.2)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gym) (1.26.4)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gym) (3.1.0)\r\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gym) (0.0.8)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:03.992839Z",
     "start_time": "2024-11-10T12:41:03.874767Z"
    }
   },
   "cell_type": "code",
   "source": "!pwd",
   "id": "4357c90b8dd6875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:19:06.727590Z",
     "start_time": "2024-11-10T13:19:06.724055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "%cd FinRL-Meta"
   ],
   "id": "edd11143ebdc4408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction/FinRL-Meta\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:04.114960Z",
     "start_time": "2024-11-10T12:41:03.998606Z"
    }
   },
   "cell_type": "code",
   "source": "!pwd",
   "id": "149faa7c5a101563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction/FinRL-Meta\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Modules",
   "id": "fe0084f11e256219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:19:09.981153Z",
     "start_time": "2024-11-10T13:19:09.975190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config\n",
    "from meta.data_processor import DataProcessor\n",
    "from main import check_and_make_directories"
   ],
   "id": "37985a7232a2dbf4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:19:17.083289Z",
     "start_time": "2024-11-10T13:19:15.981638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv\n",
    "from agents.stablebaselines3_models import DRLAgent"
   ],
   "id": "51c58616aeec5dae",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:19:20.239908Z",
     "start_time": "2024-11-10T13:19:20.237292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import List\n",
    "from argparse import ArgumentParser\n",
    "from meta.config_tickers import DOW_30_TICKER \n",
    "from meta.config import ( DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE, ERL_PARAMS, RLlib_PARAMS, SAC_PARAMS, ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL, )"
   ],
   "id": "3440d191bbe63c86",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:19:23.962461Z",
     "start_time": "2024-11-10T13:19:23.223104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "pd.options.display.max_columns = None\n",
    "print(\"All Modules have been imported\")"
   ],
   "id": "abdd2c5116622ad9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Modules have been imported\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Folders",
   "id": "3c93d79e5e4be13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:06.546912Z",
     "start_time": "2024-11-10T12:41:06.544501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ],
   "id": "7fbf86271a4a9ffa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download data, cleaning and feature engineering",
   "id": "3f8e4ff24336c4a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 600000.SH 浦发银行\n",
    "- 600009.SH 上海机场\n",
    "- 600016.SH 民生银行\n",
    "- 600028.SH 中国石化\n",
    "- 600030.SH 中信证券\n",
    "- 600031.SH 三一重工\n",
    "- 600036.SH 招商银行\n",
    "- 600050.SH 中国联通\n",
    "- 600104.SH 上汽集团\n",
    "- 600196.SH 复星医药\n",
    "- 600276.SH 恒瑞医药\n",
    "- 600309.SH 万华化学\n",
    "- 600519.SH 贵州茅台\n",
    "- 600547.SH 山东黄金\n",
    "- 600570.SH 恒生电子\n"
   ],
   "id": "5756db25f2f4661d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:05.182624Z",
     "start_time": "2024-11-10T13:33:05.179430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2019-08-01' \n",
    "TRADE_START_DATE = '2019-08-01' \n",
    "TRADE_END_DATE = '2020-01-03'"
   ],
   "id": "565ab4a9bbc618b3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:01:28.338770Z",
     "start_time": "2024-11-10T14:01:28.335511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TIME_INTERVAL = '1d'\n",
    "kwargs = {}\n",
    "kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5' \n",
    "p = DataProcessor(data_source='tushare', start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE,time_interval=TIME_INTERVAL, **kwargs)"
   ],
   "id": "cfff9d9c5430f3c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tushare successfully connected\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Download and Clean",
   "id": "dfbf3ac76b73a997"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:16.301670Z",
     "start_time": "2024-11-10T13:33:10.899627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "p.clean_data()\n",
    "p.fillna()"
   ],
   "id": "5adf5c71804e3980",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add technical indicator",
   "id": "5922180e32b080e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:20.719839Z",
     "start_time": "2024-11-10T13:33:19.008761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p.add_technical_indicator(config.INDICATORS)\n",
    "p.fillna()"
   ],
   "id": "2962ba6e8e2c46b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split training dataset",
   "id": "c55f2097054e956"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:24.570195Z",
     "start_time": "2024-11-10T13:33:24.558395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "print(f\"train.tic.unique(): {train.tic.unique()}\")\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ],
   "id": "1ff2944bcd12e114",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['600000.SH' '600009.SH' '600016.SH' '600028.SH' '600030.SH' '600031.SH'\n",
      " '600036.SH' '600050.SH' '600104.SH' '600196.SH' '600276.SH' '600309.SH'\n",
      " '600519.SH' '600547.SH' '600570.SH']\n",
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:28.051157Z",
     "start_time": "2024-11-10T13:33:28.038734Z"
    }
   },
   "cell_type": "code",
   "source": "train.head()",
   "id": "6a17bbb9588979b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:31.674323Z",
     "start_time": "2024-11-10T13:33:31.669755Z"
    }
   },
   "cell_type": "code",
   "source": "train.shape",
   "id": "42bf27f5a452d47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16695, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:34.330358Z",
     "start_time": "2024-11-10T13:33:34.326465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension * (len(config.INDICATORS) +2) +1\n",
    "print(f\"stock_dimension: {stock_dimension}, state_space: {state_space}\")"
   ],
   "id": "b61bfdfa4bd41248",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_dimension: 15, state_space: 151\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Error: AttributeError: 'DataFrame' object has no attribute 'date'\n",
    "在akshare获取的数据中并不包含date列，需要将time列转换为date"
   ],
   "id": "f096f3b759a7eb68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:37.327618Z",
     "start_time": "2024-11-10T13:33:37.316959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = train.rename(columns={'time': 'date'})\n",
    "train.head()"
   ],
   "id": "2ab7bc335449d9e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tic        date  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:13.909881Z",
     "start_time": "2024-11-10T12:41:13.908252Z"
    }
   },
   "cell_type": "code",
   "source": "## Train",
   "id": "1a394a643fb4a1f1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:40.771765Z",
     "start_time": "2024-11-10T13:33:40.764670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 6.87e-5, \n",
    "    \"sell_cost_pct\": 1.0687e-3, \n",
    "    \"reward_scaling\": 1e-4, \n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1, \n",
    "    \"initial_buy\": True, \n",
    "    \"hundred_each_trade\": True\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ],
   "id": "ca4ce2257d46d71c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:33:44.165459Z",
     "start_time": "2024-11-10T13:33:44.150845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(f\"type(env_train): {print(type(env_train))}\")"
   ],
   "id": "821ea44204fa1a89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "type(env_train): None\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:41:15.122305Z",
     "start_time": "2024-11-10T12:41:13.924760Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install 'shimmy>=2.0'",
   "id": "2664e1839fadb2d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shimmy>=2.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (2.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from shimmy>=2.0) (1.26.4)\r\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from shimmy>=2.0) (1.0.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/zhengshuang/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DDPG",
   "id": "517ff766889a483a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:43:50.553731Z",
     "start_time": "2024-11-10T13:33:51.310557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = DRLAgent(env= env_train)\n",
    "DDPG_PARAMS = { \n",
    "    \"batch_size\": 256, \n",
    "    \"buffer_size\": 50000, \n",
    "    \"learning_rate\": 0.0005, \n",
    "    \"action_noise\": \"normal\",\n",
    "} \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "\n",
    "model_ddpg = agent.get_model('ddpg', model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "trained_ddpg = agent.train_model(model=model_ddpg,tb_log_name='ddpg',total_timesteps=100000)\n",
    "trained_ddpg.save(TRAIN_START_DATE+'/ashare_trained_models_ddpg')"
   ],
   "id": "8b0aa0789ec18a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_3\n",
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1033393.15\n",
      "total_reward: 33393.15\n",
      "total_cost: 13683.85\n",
      "total_trades: 1523\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887956.42\n",
      "total_reward: -112043.58\n",
      "total_cost: 422.58\n",
      "total_trades: 79\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885661.13\n",
      "total_reward: -114338.87\n",
      "total_cost: 422.87\n",
      "total_trades: 80\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879743.08\n",
      "total_reward: -120256.92\n",
      "total_cost: 422.92\n",
      "total_trades: 81\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 166        |\n",
      "|    time_elapsed    | 26         |\n",
      "|    total_timesteps | 4452       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -325       |\n",
      "|    critic_loss     | 270        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 4351       |\n",
      "|    reward          | -0.0879559 |\n",
      "-----------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887498.13\n",
      "total_reward: -112501.87\n",
      "total_cost: 422.87\n",
      "total_trades: 81\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884620.39\n",
      "total_reward: -115379.61\n",
      "total_cost: 422.61\n",
      "total_trades: 79\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884424.19\n",
      "total_reward: -115575.81\n",
      "total_cost: 422.81\n",
      "total_trades: 82\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882247.19\n",
      "total_reward: -117752.81\n",
      "total_cost: 422.81\n",
      "total_trades: 80\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 165        |\n",
      "|    time_elapsed    | 53         |\n",
      "|    total_timesteps | 8904       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -266       |\n",
      "|    critic_loss     | 29.1       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8803       |\n",
      "|    reward          | -0.0881878 |\n",
      "-----------------------------------\n",
      "Episode: 10\n",
      "day: 1112, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884348.28\n",
      "total_reward: -115651.72\n",
      "total_cost: 422.72\n",
      "total_trades: 81\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 11\n",
      "day: 1112, episode: 11\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882574.29\n",
      "total_reward: -117425.71\n",
      "total_cost: 422.71\n",
      "total_trades: 79\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883371.29\n",
      "total_reward: -116628.71\n",
      "total_cost: 422.71\n",
      "total_trades: 81\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889675.19\n",
      "total_reward: -110324.81\n",
      "total_cost: 422.81\n",
      "total_trades: 79\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 166        |\n",
      "|    time_elapsed    | 80         |\n",
      "|    total_timesteps | 13356      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -218       |\n",
      "|    critic_loss     | 86.7       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 13255      |\n",
      "|    reward          | -0.0889641 |\n",
      "-----------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882331.33\n",
      "total_reward: -117668.67\n",
      "total_cost: 422.67\n",
      "total_trades: 79\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882954.25\n",
      "total_reward: -117045.75\n",
      "total_cost: 422.75\n",
      "total_trades: 80\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882981.17\n",
      "total_reward: -117018.83\n",
      "total_cost: 422.83\n",
      "total_trades: 81\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 875776.37\n",
      "total_reward: -124223.63\n",
      "total_cost: 422.63\n",
      "total_trades: 82\n",
      "Sharpe: 0.046\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 162        |\n",
      "|    time_elapsed    | 109        |\n",
      "|    total_timesteps | 17808      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -161       |\n",
      "|    critic_loss     | 8.04       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 17707      |\n",
      "|    reward          | -0.0875734 |\n",
      "-----------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887256.21\n",
      "total_reward: -112743.79\n",
      "total_cost: 422.79\n",
      "total_trades: 81\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 888752.23\n",
      "total_reward: -111247.77\n",
      "total_cost: 422.77\n",
      "total_trades: 80\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887438.33\n",
      "total_reward: -112561.67\n",
      "total_cost: 422.67\n",
      "total_trades: 81\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882995.22\n",
      "total_reward: -117004.78\n",
      "total_cost: 422.78\n",
      "total_trades: 79\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 163        |\n",
      "|    time_elapsed    | 136        |\n",
      "|    total_timesteps | 22260      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -125       |\n",
      "|    critic_loss     | 1.88       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 22159      |\n",
      "|    reward          | -0.0882981 |\n",
      "-----------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879395.43\n",
      "total_reward: -120604.57\n",
      "total_cost: 422.57\n",
      "total_trades: 80\n",
      "Sharpe: 0.050\n",
      "=================================\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889009.33\n",
      "total_reward: -110990.67\n",
      "total_cost: 422.67\n",
      "total_trades: 81\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884435.29\n",
      "total_reward: -115564.71\n",
      "total_cost: 422.71\n",
      "total_trades: 81\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887476.20\n",
      "total_reward: -112523.80\n",
      "total_cost: 422.80\n",
      "total_trades: 80\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 163        |\n",
      "|    time_elapsed    | 163        |\n",
      "|    total_timesteps | 26712      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -97.2      |\n",
      "|    critic_loss     | 1.43       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 26611      |\n",
      "|    reward          | -0.0887208 |\n",
      "-----------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879477.16\n",
      "total_reward: -120522.84\n",
      "total_cost: 422.84\n",
      "total_trades: 79\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887620.29\n",
      "total_reward: -112379.71\n",
      "total_cost: 422.71\n",
      "total_trades: 80\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886942.16\n",
      "total_reward: -113057.84\n",
      "total_cost: 422.84\n",
      "total_trades: 82\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 891883.16\n",
      "total_reward: -108116.84\n",
      "total_cost: 422.84\n",
      "total_trades: 81\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 163        |\n",
      "|    time_elapsed    | 190        |\n",
      "|    total_timesteps | 31164      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -75.9      |\n",
      "|    critic_loss     | 1.24       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 31063      |\n",
      "|    reward          | -0.0891878 |\n",
      "-----------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 890221.21\n",
      "total_reward: -109778.79\n",
      "total_cost: 422.79\n",
      "total_trades: 79\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887031.21\n",
      "total_reward: -112968.79\n",
      "total_cost: 422.79\n",
      "total_trades: 79\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887707.15\n",
      "total_reward: -112292.85\n",
      "total_cost: 422.85\n",
      "total_trades: 82\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 880555.12\n",
      "total_reward: -119444.88\n",
      "total_cost: 422.88\n",
      "total_trades: 81\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 164        |\n",
      "|    time_elapsed    | 217        |\n",
      "|    total_timesteps | 35616      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -53.9      |\n",
      "|    critic_loss     | 0.303      |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 35515      |\n",
      "|    reward          | -0.0880539 |\n",
      "-----------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883570.42\n",
      "total_reward: -116429.58\n",
      "total_cost: 422.58\n",
      "total_trades: 82\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883532.16\n",
      "total_reward: -116467.84\n",
      "total_cost: 422.84\n",
      "total_trades: 82\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889262.22\n",
      "total_reward: -110737.78\n",
      "total_cost: 422.78\n",
      "total_trades: 80\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884700.38\n",
      "total_reward: -115299.62\n",
      "total_cost: 422.62\n",
      "total_trades: 82\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 164        |\n",
      "|    time_elapsed    | 242        |\n",
      "|    total_timesteps | 40068      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -39.5      |\n",
      "|    critic_loss     | 1.3        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 39967      |\n",
      "|    reward          | -0.0884291 |\n",
      "-----------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883191.13\n",
      "total_reward: -116808.87\n",
      "total_cost: 422.87\n",
      "total_trades: 83\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 892529.34\n",
      "total_reward: -107470.66\n",
      "total_cost: 422.66\n",
      "total_trades: 80\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885015.34\n",
      "total_reward: -114984.66\n",
      "total_cost: 422.66\n",
      "total_trades: 82\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885360.16\n",
      "total_reward: -114639.84\n",
      "total_cost: 422.84\n",
      "total_trades: 81\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 165        |\n",
      "|    time_elapsed    | 268        |\n",
      "|    total_timesteps | 44520      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -28.3      |\n",
      "|    critic_loss     | 0.53       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 44419      |\n",
      "|    reward          | -0.0885291 |\n",
      "-----------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882859.05\n",
      "total_reward: -117140.95\n",
      "total_cost: 422.95\n",
      "total_trades: 80\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 877607.23\n",
      "total_reward: -122392.77\n",
      "total_cost: 422.77\n",
      "total_trades: 80\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882065.16\n",
      "total_reward: -117934.84\n",
      "total_cost: 422.84\n",
      "total_trades: 79\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879490.17\n",
      "total_reward: -120509.83\n",
      "total_cost: 422.83\n",
      "total_trades: 80\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 166        |\n",
      "|    time_elapsed    | 294        |\n",
      "|    total_timesteps | 48972      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -20.9      |\n",
      "|    critic_loss     | 0.405      |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 48871      |\n",
      "|    reward          | -0.0879188 |\n",
      "-----------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886717.04\n",
      "total_reward: -113282.96\n",
      "total_cost: 422.96\n",
      "total_trades: 81\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887524.14\n",
      "total_reward: -112475.86\n",
      "total_cost: 422.86\n",
      "total_trades: 78\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883653.10\n",
      "total_reward: -116346.90\n",
      "total_cost: 422.90\n",
      "total_trades: 80\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886164.20\n",
      "total_reward: -113835.80\n",
      "total_cost: 422.80\n",
      "total_trades: 81\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 166        |\n",
      "|    time_elapsed    | 320        |\n",
      "|    total_timesteps | 53424      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -14.4      |\n",
      "|    critic_loss     | 0.351      |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 53323      |\n",
      "|    reward          | -0.0886146 |\n",
      "-----------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889876.26\n",
      "total_reward: -110123.74\n",
      "total_cost: 422.74\n",
      "total_trades: 81\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 891736.17\n",
      "total_reward: -108263.83\n",
      "total_cost: 422.83\n",
      "total_trades: 80\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885404.20\n",
      "total_reward: -114595.80\n",
      "total_cost: 422.80\n",
      "total_trades: 79\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884772.21\n",
      "total_reward: -115227.79\n",
      "total_cost: 422.79\n",
      "total_trades: 80\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 166        |\n",
      "|    time_elapsed    | 346        |\n",
      "|    total_timesteps | 57876      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -8.32      |\n",
      "|    critic_loss     | 0.1        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 57775      |\n",
      "|    reward          | -0.0884476 |\n",
      "-----------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881482.14\n",
      "total_reward: -118517.86\n",
      "total_cost: 422.86\n",
      "total_trades: 80\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "Episode: 55\n",
      "day: 1112, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879441.32\n",
      "total_reward: -120558.68\n",
      "total_cost: 422.68\n",
      "total_trades: 81\n",
      "Sharpe: 0.050\n",
      "=================================\n",
      "Episode: 56\n",
      "day: 1112, episode: 56\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881875.40\n",
      "total_reward: -118124.60\n",
      "total_cost: 422.60\n",
      "total_trades: 79\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 57\n",
      "day: 1112, episode: 57\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887174.31\n",
      "total_reward: -112825.69\n",
      "total_cost: 422.69\n",
      "total_trades: 80\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 372        |\n",
      "|    total_timesteps | 62328      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -4.32      |\n",
      "|    critic_loss     | 0.115      |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 62227      |\n",
      "|    reward          | -0.0887022 |\n",
      "-----------------------------------\n",
      "Episode: 58\n",
      "day: 1112, episode: 58\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883325.27\n",
      "total_reward: -116674.73\n",
      "total_cost: 422.73\n",
      "total_trades: 79\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 59\n",
      "day: 1112, episode: 59\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881685.43\n",
      "total_reward: -118314.57\n",
      "total_cost: 422.57\n",
      "total_trades: 80\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 60\n",
      "day: 1112, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 893276.37\n",
      "total_reward: -106723.63\n",
      "total_cost: 422.63\n",
      "total_trades: 80\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "Episode: 61\n",
      "day: 1112, episode: 61\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882854.12\n",
      "total_reward: -117145.88\n",
      "total_cost: 422.88\n",
      "total_trades: 80\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 398        |\n",
      "|    total_timesteps | 66780      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -1.88      |\n",
      "|    critic_loss     | 0.0208     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 66679      |\n",
      "|    reward          | -0.0882795 |\n",
      "-----------------------------------\n",
      "Episode: 62\n",
      "day: 1112, episode: 62\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 876837.37\n",
      "total_reward: -123162.63\n",
      "total_cost: 422.63\n",
      "total_trades: 81\n",
      "Sharpe: 0.046\n",
      "=================================\n",
      "Episode: 63\n",
      "day: 1112, episode: 63\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886467.05\n",
      "total_reward: -113532.95\n",
      "total_cost: 422.95\n",
      "total_trades: 80\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 64\n",
      "day: 1112, episode: 64\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881889.14\n",
      "total_reward: -118110.86\n",
      "total_cost: 422.86\n",
      "total_trades: 81\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 65\n",
      "day: 1112, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883609.30\n",
      "total_reward: -116390.70\n",
      "total_cost: 422.70\n",
      "total_trades: 81\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 64         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 424        |\n",
      "|    total_timesteps | 71232      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.833      |\n",
      "|    critic_loss     | 0.0455     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 71131      |\n",
      "|    reward          | -0.0883249 |\n",
      "-----------------------------------\n",
      "Episode: 66\n",
      "day: 1112, episode: 66\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881049.30\n",
      "total_reward: -118950.70\n",
      "total_cost: 422.70\n",
      "total_trades: 80\n",
      "Sharpe: 0.050\n",
      "=================================\n",
      "Episode: 67\n",
      "day: 1112, episode: 67\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 878700.73\n",
      "total_reward: -121299.27\n",
      "total_cost: 422.27\n",
      "total_trades: 80\n",
      "Sharpe: 0.050\n",
      "=================================\n",
      "Episode: 68\n",
      "day: 1112, episode: 68\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884527.33\n",
      "total_reward: -115472.67\n",
      "total_cost: 422.67\n",
      "total_trades: 80\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "Episode: 69\n",
      "day: 1112, episode: 69\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 877724.18\n",
      "total_reward: -122275.82\n",
      "total_cost: 422.82\n",
      "total_trades: 82\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 68         |\n",
      "|    fps             | 168        |\n",
      "|    time_elapsed    | 450        |\n",
      "|    total_timesteps | 75684      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.78       |\n",
      "|    critic_loss     | 0.0288     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 75583      |\n",
      "|    reward          | -0.0877714 |\n",
      "-----------------------------------\n",
      "Episode: 70\n",
      "day: 1112, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885063.35\n",
      "total_reward: -114936.65\n",
      "total_cost: 422.65\n",
      "total_trades: 78\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 71\n",
      "day: 1112, episode: 71\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879159.38\n",
      "total_reward: -120840.62\n",
      "total_cost: 422.62\n",
      "total_trades: 81\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "Episode: 72\n",
      "day: 1112, episode: 72\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882769.15\n",
      "total_reward: -117230.85\n",
      "total_cost: 422.85\n",
      "total_trades: 80\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "Episode: 73\n",
      "day: 1112, episode: 73\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879552.13\n",
      "total_reward: -120447.87\n",
      "total_cost: 422.87\n",
      "total_trades: 80\n",
      "Sharpe: 0.051\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 168        |\n",
      "|    time_elapsed    | 476        |\n",
      "|    total_timesteps | 80136      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.42       |\n",
      "|    critic_loss     | 0.0371     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 80035      |\n",
      "|    reward          | -0.0879538 |\n",
      "-----------------------------------\n",
      "Episode: 74\n",
      "day: 1112, episode: 74\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885691.15\n",
      "total_reward: -114308.85\n",
      "total_cost: 422.85\n",
      "total_trades: 81\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "Episode: 75\n",
      "day: 1112, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889188.22\n",
      "total_reward: -110811.78\n",
      "total_cost: 422.78\n",
      "total_trades: 81\n",
      "Sharpe: 0.060\n",
      "=================================\n",
      "Episode: 76\n",
      "day: 1112, episode: 76\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 890369.18\n",
      "total_reward: -109630.82\n",
      "total_cost: 422.82\n",
      "total_trades: 79\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "Episode: 77\n",
      "day: 1112, episode: 77\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 884850.27\n",
      "total_reward: -115149.73\n",
      "total_cost: 422.73\n",
      "total_trades: 81\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 76         |\n",
      "|    fps             | 168        |\n",
      "|    time_elapsed    | 501        |\n",
      "|    total_timesteps | 84588      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.61       |\n",
      "|    critic_loss     | 0.019      |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 84487      |\n",
      "|    reward          | -0.0884528 |\n",
      "-----------------------------------\n",
      "Episode: 78\n",
      "day: 1112, episode: 78\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 879249.27\n",
      "total_reward: -120750.73\n",
      "total_cost: 422.73\n",
      "total_trades: 80\n",
      "Sharpe: 0.051\n",
      "=================================\n",
      "Episode: 79\n",
      "day: 1112, episode: 79\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883846.42\n",
      "total_reward: -116153.58\n",
      "total_cost: 422.58\n",
      "total_trades: 80\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "Episode: 80\n",
      "day: 1112, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 890227.17\n",
      "total_reward: -109772.83\n",
      "total_cost: 422.83\n",
      "total_trades: 81\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "Episode: 81\n",
      "day: 1112, episode: 81\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 890788.48\n",
      "total_reward: -109211.52\n",
      "total_cost: 422.52\n",
      "total_trades: 81\n",
      "Sharpe: 0.060\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 80         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 530        |\n",
      "|    total_timesteps | 89040      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.45       |\n",
      "|    critic_loss     | 0.0132     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 88939      |\n",
      "|    reward          | -0.0890497 |\n",
      "-----------------------------------\n",
      "Episode: 82\n",
      "day: 1112, episode: 82\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886217.40\n",
      "total_reward: -113782.60\n",
      "total_cost: 422.60\n",
      "total_trades: 80\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "Episode: 83\n",
      "day: 1112, episode: 83\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 888817.03\n",
      "total_reward: -111182.97\n",
      "total_cost: 422.97\n",
      "total_trades: 79\n",
      "Sharpe: 0.060\n",
      "=================================\n",
      "Episode: 84\n",
      "day: 1112, episode: 84\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881776.35\n",
      "total_reward: -118223.65\n",
      "total_cost: 422.65\n",
      "total_trades: 80\n",
      "Sharpe: 0.051\n",
      "=================================\n",
      "Episode: 85\n",
      "day: 1112, episode: 85\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885871.27\n",
      "total_reward: -114128.73\n",
      "total_cost: 422.73\n",
      "total_trades: 82\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 84         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 558        |\n",
      "|    total_timesteps | 93492      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.1        |\n",
      "|    critic_loss     | 0.0118     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 93391      |\n",
      "|    reward          | -0.0885858 |\n",
      "-----------------------------------\n",
      "Episode: 86\n",
      "day: 1112, episode: 86\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883554.34\n",
      "total_reward: -116445.66\n",
      "total_cost: 422.66\n",
      "total_trades: 82\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "Episode: 87\n",
      "day: 1112, episode: 87\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889445.14\n",
      "total_reward: -110554.86\n",
      "total_cost: 422.86\n",
      "total_trades: 80\n",
      "Sharpe: 0.060\n",
      "=================================\n",
      "Episode: 88\n",
      "day: 1112, episode: 88\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886301.16\n",
      "total_reward: -113698.84\n",
      "total_cost: 422.84\n",
      "total_trades: 78\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "Episode: 89\n",
      "day: 1112, episode: 89\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 887254.24\n",
      "total_reward: -112745.76\n",
      "total_cost: 422.76\n",
      "total_trades: 80\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 88         |\n",
      "|    fps             | 167        |\n",
      "|    time_elapsed    | 585        |\n",
      "|    total_timesteps | 97944      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.4        |\n",
      "|    critic_loss     | 0.0132     |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 97843      |\n",
      "|    reward          | -0.0886971 |\n",
      "-----------------------------------\n",
      "Episode: 90\n",
      "day: 1112, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 880198.18\n",
      "total_reward: -119801.82\n",
      "total_cost: 422.82\n",
      "total_trades: 79\n",
      "Sharpe: 0.051\n",
      "=================================\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A2C",
   "id": "67f9e66f01997547"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:45:14.724263Z",
     "start_time": "2024-11-10T13:43:50.554928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = DRLAgent(env= env_train)\n",
    "model_a2c = agent.get_model('a2c')\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c',total_timesteps=50000)\n",
    "trained_a2c.save(TRAIN_START_DATE+'/ashare_trained_models_a2c')"
   ],
   "id": "d0c94929a7c37f02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_3\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 599         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | -77.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -7.33       |\n",
      "|    reward             | -0.03825828 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 605          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | -10.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 5.14         |\n",
      "|    reward             | -0.016008494 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.0621       |\n",
      "----------------------------------------\n",
      "Episode: 92\n",
      "day: 1112, episode: 92\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1171912.21\n",
      "total_reward: 171912.21\n",
      "total_cost: 92670.79\n",
      "total_trades: 9678\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 608          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -1.13        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 2.74         |\n",
      "|    reward             | -0.014993075 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.0225       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 605          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -132         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 1.92         |\n",
      "|    reward             | -0.009746862 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.0452       |\n",
      "----------------------------------------\n",
      "Episode: 93\n",
      "day: 1112, episode: 93\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1354783.47\n",
      "total_reward: 354783.47\n",
      "total_cost: 106727.53\n",
      "total_trades: 10726\n",
      "Sharpe: 0.383\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 604          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | -122         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 6.95         |\n",
      "|    reward             | -0.029424457 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.214        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 605          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | -1.09        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | -0.013360687 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.00348      |\n",
      "----------------------------------------\n",
      "Episode: 94\n",
      "day: 1112, episode: 94\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1102813.67\n",
      "total_reward: 102813.67\n",
      "total_cost: 71892.33\n",
      "total_trades: 8671\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 606         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | -157        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.0718     |\n",
      "|    reward             | -0.01464466 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.0292      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 607          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | -126         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -11.9        |\n",
      "|    reward             | -0.006825539 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.281        |\n",
      "----------------------------------------\n",
      "Episode: 95\n",
      "day: 1112, episode: 95\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1320761.37\n",
      "total_reward: 320761.37\n",
      "total_cost: 72491.63\n",
      "total_trades: 8558\n",
      "Sharpe: 0.382\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 607         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.268       |\n",
      "|    reward             | -0.00548418 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.000168    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 609         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | -0.169      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.25        |\n",
      "|    reward             | -0.01318919 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0019      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 609          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | -55.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 5.43         |\n",
      "|    reward             | -0.009054058 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.0472       |\n",
      "----------------------------------------\n",
      "Episode: 96\n",
      "day: 1112, episode: 96\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 756566.07\n",
      "total_reward: -243433.93\n",
      "total_cost: 55221.93\n",
      "total_trades: 7584\n",
      "Sharpe: -0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 608           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | -21.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -1.73         |\n",
      "|    reward             | -0.0015305671 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.0124        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 609           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.2         |\n",
      "|    explained_variance | -2.62         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.505         |\n",
      "|    reward             | -0.0039239144 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.0007        |\n",
      "-----------------------------------------\n",
      "Episode: 97\n",
      "day: 1112, episode: 97\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 801482.23\n",
      "total_reward: -198517.77\n",
      "total_cost: 40141.77\n",
      "total_trades: 6149\n",
      "Sharpe: -0.093\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 609           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.5         |\n",
      "|    explained_variance | -0.154        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -1.06         |\n",
      "|    reward             | -0.0005652252 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.0034        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 610         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | -7.65       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.839      |\n",
      "|    reward             | -0.00382128 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.00392     |\n",
      "---------------------------------------\n",
      "Episode: 98\n",
      "day: 1112, episode: 98\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 769013.81\n",
      "total_reward: -230986.19\n",
      "total_cost: 27558.19\n",
      "total_trades: 4976\n",
      "Sharpe: -0.141\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 611           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24           |\n",
      "|    explained_variance | -23.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0363        |\n",
      "|    reward             | -0.0043814545 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 5.21e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 611           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | 0.188         |\n",
      "|    reward             | -0.0030351027 |\n",
      "|    std                | 1.23          |\n",
      "|    value_loss         | 7.87e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 99\n",
      "day: 1112, episode: 99\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 726069.63\n",
      "total_reward: -273930.37\n",
      "total_cost: 25055.37\n",
      "total_trades: 4370\n",
      "Sharpe: -0.204\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | -124        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 1.01        |\n",
      "|    reward             | -0.00465483 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.00492     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 612           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.2         |\n",
      "|    explained_variance | -34.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.289        |\n",
      "|    reward             | -0.0014652318 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 0.000373      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 613           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.6         |\n",
      "|    explained_variance | 0.0126        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.659        |\n",
      "|    reward             | -0.0005819212 |\n",
      "|    std                | 1.33          |\n",
      "|    value_loss         | 0.00127       |\n",
      "-----------------------------------------\n",
      "Episode: 100\n",
      "day: 1112, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 792819.20\n",
      "total_reward: -207180.80\n",
      "total_cost: 26879.80\n",
      "total_trades: 4192\n",
      "Sharpe: -0.091\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 613            |\n",
      "|    iterations         | 2100           |\n",
      "|    time_elapsed       | 17             |\n",
      "|    total_timesteps    | 10500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -26.1          |\n",
      "|    explained_variance | 0.705          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2099           |\n",
      "|    policy_loss        | -0.0642        |\n",
      "|    reward             | -0.00023959811 |\n",
      "|    std                | 1.38           |\n",
      "|    value_loss         | 6.83e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 614           |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | -1.38         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | -2.62         |\n",
      "|    reward             | -0.0026007032 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 0.0107        |\n",
      "-----------------------------------------\n",
      "Episode: 101\n",
      "day: 1112, episode: 101\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 818983.60\n",
      "total_reward: -181016.40\n",
      "total_cost: 26392.40\n",
      "total_trades: 4117\n",
      "Sharpe: -0.095\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 613           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27           |\n",
      "|    explained_variance | -3.11         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | 0.122         |\n",
      "|    reward             | -0.0011221152 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 614           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | -52           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | -0.329        |\n",
      "|    reward             | -0.0011807414 |\n",
      "|    std                | 1.52          |\n",
      "|    value_loss         | 0.000596      |\n",
      "-----------------------------------------\n",
      "Episode: 102\n",
      "day: 1112, episode: 102\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 829143.94\n",
      "total_reward: -170856.06\n",
      "total_cost: 27427.06\n",
      "total_trades: 4421\n",
      "Sharpe: -0.111\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 613         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 0.0508      |\n",
      "|    reward             | -0.00889681 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 3.86e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0.0716      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.81       |\n",
      "|    reward             | -0.05767889 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 0.00155     |\n",
      "---------------------------------------\n",
      "Episode: 103\n",
      "day: 1112, episode: 103\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 775828.64\n",
      "total_reward: -224171.36\n",
      "total_cost: 24199.36\n",
      "total_trades: 3687\n",
      "Sharpe: -0.270\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 612           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.4         |\n",
      "|    explained_variance | -0.739        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | 0.303         |\n",
      "|    reward             | -0.0003456297 |\n",
      "|    std                | 1.72          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 612          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.0258      |\n",
      "|    reward             | -0.004249247 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 1.25e-06     |\n",
      "----------------------------------------\n",
      "Episode: 104\n",
      "day: 1112, episode: 104\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 795153.66\n",
      "total_reward: -204846.34\n",
      "total_cost: 29223.34\n",
      "total_trades: 3987\n",
      "Sharpe: -0.179\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 612          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.114       |\n",
      "|    reward             | -0.004333899 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 3.4e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 612           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.234         |\n",
      "|    reward             | -0.0054013166 |\n",
      "|    std                | 1.94          |\n",
      "|    value_loss         | 8.38e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 612           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | -0.0474       |\n",
      "|    reward             | -0.0020457043 |\n",
      "|    std                | 2.03          |\n",
      "|    value_loss         | 4e-06         |\n",
      "-----------------------------------------\n",
      "Episode: 105\n",
      "day: 1112, episode: 105\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 863880.17\n",
      "total_reward: -136119.83\n",
      "total_cost: 31209.83\n",
      "total_trades: 4203\n",
      "Sharpe: -0.205\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 612            |\n",
      "|    iterations         | 3200           |\n",
      "|    time_elapsed       | 26             |\n",
      "|    total_timesteps    | 16000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -32.6          |\n",
      "|    explained_variance | -12.9          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3199           |\n",
      "|    policy_loss        | 0.0703         |\n",
      "|    reward             | -0.00033156064 |\n",
      "|    std                | 2.13           |\n",
      "|    value_loss         | 8.02e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 612          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.267        |\n",
      "|    reward             | -0.004136375 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 8.32e-05     |\n",
      "----------------------------------------\n",
      "Episode: 106\n",
      "day: 1112, episode: 106\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 778255.60\n",
      "total_reward: -221744.40\n",
      "total_cost: 33406.40\n",
      "total_trades: 4446\n",
      "Sharpe: -0.355\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 612           |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.0256        |\n",
      "|    reward             | -0.0001584909 |\n",
      "|    std                | 2.34          |\n",
      "|    value_loss         | 5.16e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 611           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | -0.00488      |\n",
      "|    reward             | -0.0065669473 |\n",
      "|    std                | 2.48          |\n",
      "|    value_loss         | 1.5e-06       |\n",
      "-----------------------------------------\n",
      "Episode: 107\n",
      "day: 1112, episode: 107\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1004746.77\n",
      "total_reward: 4746.77\n",
      "total_cost: 30681.23\n",
      "total_trades: 4210\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 611          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | -0.542       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | -0.008335872 |\n",
      "|    std                | 2.63         |\n",
      "|    value_loss         | 1.32e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 611           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | 0.0713        |\n",
      "|    reward             | -0.0001789841 |\n",
      "|    std                | 2.78          |\n",
      "|    value_loss         | 4.49e-06      |\n",
      "-----------------------------------------\n",
      "Episode: 108\n",
      "day: 1112, episode: 108\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 809132.97\n",
      "total_reward: -190867.03\n",
      "total_cost: 30957.03\n",
      "total_trades: 4506\n",
      "Sharpe: -0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 609           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.0661        |\n",
      "|    reward             | -0.0014235701 |\n",
      "|    std                | 2.92          |\n",
      "|    value_loss         | 4.62e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 606           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 32            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 0.154         |\n",
      "|    reward             | -0.0011976353 |\n",
      "|    std                | 3.07          |\n",
      "|    value_loss         | 1.49e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 606          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.7        |\n",
      "|    explained_variance | 0.118        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.323        |\n",
      "|    reward             | -0.001566825 |\n",
      "|    std                | 3.21         |\n",
      "|    value_loss         | 8.53e-05     |\n",
      "----------------------------------------\n",
      "Episode: 109\n",
      "day: 1112, episode: 109\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 754601.72\n",
      "total_reward: -245398.28\n",
      "total_cost: 33377.28\n",
      "total_trades: 4283\n",
      "Sharpe: -0.342\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 606           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.4         |\n",
      "|    explained_variance | -0.253        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | 0.142         |\n",
      "|    reward             | -0.0020024641 |\n",
      "|    std                | 3.35          |\n",
      "|    value_loss         | 1.6e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 605           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 34            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | 0.285         |\n",
      "|    reward             | -0.0023816542 |\n",
      "|    std                | 3.48          |\n",
      "|    value_loss         | 6.94e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 110\n",
      "day: 1112, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 733171.53\n",
      "total_reward: -266828.47\n",
      "total_cost: 30851.47\n",
      "total_trades: 4128\n",
      "Sharpe: -0.296\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 605          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.158        |\n",
      "|    reward             | -0.009002728 |\n",
      "|    std                | 3.63         |\n",
      "|    value_loss         | 2.06e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 604           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 36            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.133         |\n",
      "|    reward             | -0.0027677177 |\n",
      "|    std                | 3.81          |\n",
      "|    value_loss         | 1.3e-05       |\n",
      "-----------------------------------------\n",
      "Episode: 111\n",
      "day: 1112, episode: 111\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 855656.22\n",
      "total_reward: -144343.78\n",
      "total_cost: 33118.78\n",
      "total_trades: 4031\n",
      "Sharpe: -0.190\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 604          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.552        |\n",
      "|    reward             | -0.005127333 |\n",
      "|    std                | 4.01         |\n",
      "|    value_loss         | 0.000213     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 604            |\n",
      "|    iterations         | 4600           |\n",
      "|    time_elapsed       | 38             |\n",
      "|    total_timesteps    | 23000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.7          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4599           |\n",
      "|    policy_loss        | 0.13           |\n",
      "|    reward             | -0.00083220145 |\n",
      "|    std                | 4.19           |\n",
      "|    value_loss         | 1.19e-05       |\n",
      "------------------------------------------\n",
      "Episode: 112\n",
      "day: 1112, episode: 112\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 728097.33\n",
      "total_reward: -271902.67\n",
      "total_cost: 37967.67\n",
      "total_trades: 4429\n",
      "Sharpe: -0.373\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 603           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | -0.261        |\n",
      "|    reward             | -0.0010335341 |\n",
      "|    std                | 4.37          |\n",
      "|    value_loss         | 0.000322      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 603          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44          |\n",
      "|    explained_variance | -0.753       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | -9.23328e-05 |\n",
      "|    std                | 4.56         |\n",
      "|    value_loss         | 1.07e-05     |\n",
      "----------------------------------------\n",
      "Episode: 113\n",
      "day: 1112, episode: 113\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 728136.57\n",
      "total_reward: -271863.43\n",
      "total_cost: 39761.43\n",
      "total_trades: 4569\n",
      "Sharpe: -0.314\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 603            |\n",
      "|    iterations         | 4900           |\n",
      "|    time_elapsed       | 40             |\n",
      "|    total_timesteps    | 24500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.6          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4899           |\n",
      "|    policy_loss        | 0.183          |\n",
      "|    reward             | -0.00063355826 |\n",
      "|    std                | 4.77           |\n",
      "|    value_loss         | 1.85e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 602          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.241        |\n",
      "|    reward             | -0.003571257 |\n",
      "|    std                | 5.02         |\n",
      "|    value_loss         | 3.74e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 602           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 42            |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46           |\n",
      "|    explained_variance | -0.0316       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | -1.67         |\n",
      "|    reward             | -0.0028205784 |\n",
      "|    std                | 5.24          |\n",
      "|    value_loss         | 0.00195       |\n",
      "-----------------------------------------\n",
      "Episode: 114\n",
      "day: 1112, episode: 114\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 712499.02\n",
      "total_reward: -287500.98\n",
      "total_cost: 44712.98\n",
      "total_trades: 4915\n",
      "Sharpe: -0.424\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 601           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 43            |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.7         |\n",
      "|    explained_variance | -25.8         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.215         |\n",
      "|    reward             | -0.0005630996 |\n",
      "|    std                | 5.49          |\n",
      "|    value_loss         | 0.000693      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 601            |\n",
      "|    iterations         | 5300           |\n",
      "|    time_elapsed       | 44             |\n",
      "|    total_timesteps    | 26500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -47.4          |\n",
      "|    explained_variance | 0.255          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5299           |\n",
      "|    policy_loss        | 0.39           |\n",
      "|    reward             | -0.00028037844 |\n",
      "|    std                | 5.73           |\n",
      "|    value_loss         | 7.2e-05        |\n",
      "------------------------------------------\n",
      "Episode: 115\n",
      "day: 1112, episode: 115\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 778338.63\n",
      "total_reward: -221661.37\n",
      "total_cost: 48432.37\n",
      "total_trades: 5236\n",
      "Sharpe: -0.285\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 601          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.0969       |\n",
      "|    reward             | -0.004571057 |\n",
      "|    std                | 5.98         |\n",
      "|    value_loss         | 5.51e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 601          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.7        |\n",
      "|    explained_variance | 0.659        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -1.27        |\n",
      "|    reward             | -0.005555581 |\n",
      "|    std                | 6.27         |\n",
      "|    value_loss         | 0.000893     |\n",
      "----------------------------------------\n",
      "Episode: 116\n",
      "day: 1112, episode: 116\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 869774.95\n",
      "total_reward: -130225.05\n",
      "total_cost: 55577.05\n",
      "total_trades: 5355\n",
      "Sharpe: -0.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 601           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 46            |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 0.395         |\n",
      "|    reward             | -0.0071751913 |\n",
      "|    std                | 6.57          |\n",
      "|    value_loss         | 7.45e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 601           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 47            |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | 0.195         |\n",
      "|    reward             | -0.0030468602 |\n",
      "|    std                | 6.93          |\n",
      "|    value_loss         | 1.77e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 117\n",
      "day: 1112, episode: 117\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 795897.26\n",
      "total_reward: -204102.74\n",
      "total_cost: 51386.74\n",
      "total_trades: 5413\n",
      "Sharpe: -0.339\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 600          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.445       |\n",
      "|    reward             | -0.006705482 |\n",
      "|    std                | 7.28         |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 598          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.0513       |\n",
      "|    reward             | -0.006244102 |\n",
      "|    std                | 7.64         |\n",
      "|    value_loss         | 1.43e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 597          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | 0.0989       |\n",
      "|    reward             | -0.004964642 |\n",
      "|    std                | 8.04         |\n",
      "|    value_loss         | 6.38e-06     |\n",
      "----------------------------------------\n",
      "Episode: 118\n",
      "day: 1112, episode: 118\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 823133.71\n",
      "total_reward: -176866.29\n",
      "total_cost: 54879.29\n",
      "total_trades: 5451\n",
      "Sharpe: -0.342\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 597           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -0.294        |\n",
      "|    reward             | -0.0007059786 |\n",
      "|    std                | 8.47          |\n",
      "|    value_loss         | 5.72e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 597           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.515         |\n",
      "|    reward             | -0.0014434345 |\n",
      "|    std                | 8.94          |\n",
      "|    value_loss         | 9.32e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 119\n",
      "day: 1112, episode: 119\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 933594.61\n",
      "total_reward: -66405.39\n",
      "total_cost: 59474.39\n",
      "total_trades: 5869\n",
      "Sharpe: -0.080\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 597           |\n",
      "|    iterations         | 6300          |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 31500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.8         |\n",
      "|    explained_variance | 0.0441        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6299          |\n",
      "|    policy_loss        | 0.692         |\n",
      "|    reward             | -0.0025689984 |\n",
      "|    std                | 9.42          |\n",
      "|    value_loss         | 0.000214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 597           |\n",
      "|    iterations         | 6400          |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 32000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.5         |\n",
      "|    explained_variance | -0.382        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6399          |\n",
      "|    policy_loss        | -0.813        |\n",
      "|    reward             | -0.0026787862 |\n",
      "|    std                | 9.86          |\n",
      "|    value_loss         | 0.000254      |\n",
      "-----------------------------------------\n",
      "Episode: 120\n",
      "day: 1112, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697787.38\n",
      "total_reward: -302212.62\n",
      "total_cost: 65896.62\n",
      "total_trades: 6305\n",
      "Sharpe: -0.503\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 596           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | 0.294         |\n",
      "|    reward             | -0.0036839491 |\n",
      "|    std                | 10.3          |\n",
      "|    value_loss         | 5.37e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 596         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.0146      |\n",
      "|    reward             | -0.00394735 |\n",
      "|    std                | 10.8        |\n",
      "|    value_loss         | 4.6e-06     |\n",
      "---------------------------------------\n",
      "Episode: 121\n",
      "day: 1112, episode: 121\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1007872.76\n",
      "total_reward: 7872.76\n",
      "total_cost: 70549.24\n",
      "total_trades: 6734\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 596           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | 0.113         |\n",
      "|    reward             | -0.0035594713 |\n",
      "|    std                | 11.4          |\n",
      "|    value_loss         | 7.31e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 596          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.3        |\n",
      "|    explained_variance | -0.571       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -3.05        |\n",
      "|    reward             | -0.009570923 |\n",
      "|    std                | 12           |\n",
      "|    value_loss         | 0.00271      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 596          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.23         |\n",
      "|    reward             | -0.014693899 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 3.54e-05     |\n",
      "----------------------------------------\n",
      "Episode: 122\n",
      "day: 1112, episode: 122\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 724054.07\n",
      "total_reward: -275945.93\n",
      "total_cost: 72374.93\n",
      "total_trades: 7089\n",
      "Sharpe: -0.359\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 596          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.808       |\n",
      "|    reward             | -0.040533338 |\n",
      "|    std                | 13           |\n",
      "|    value_loss         | 0.000485     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 596          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.2        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.15         |\n",
      "|    reward             | -0.004193164 |\n",
      "|    std                | 13.6         |\n",
      "|    value_loss         | 1.2e-05      |\n",
      "----------------------------------------\n",
      "Episode: 123\n",
      "day: 1112, episode: 123\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 941805.62\n",
      "total_reward: -58194.38\n",
      "total_cost: 79606.38\n",
      "total_trades: 7329\n",
      "Sharpe: -0.101\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 596           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 60            |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -60.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | 0.37          |\n",
      "|    reward             | -0.0037917497 |\n",
      "|    std                | 14.2          |\n",
      "|    value_loss         | 5.06e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 595           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -61.5         |\n",
      "|    explained_variance | 0.341         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.259        |\n",
      "|    reward             | -0.0008681731 |\n",
      "|    std                | 14.8          |\n",
      "|    value_loss         | 4.93e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 124\n",
      "day: 1112, episode: 124\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 844787.63\n",
      "total_reward: -155212.37\n",
      "total_cost: 82958.37\n",
      "total_trades: 7726\n",
      "Sharpe: -0.212\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 595          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.782        |\n",
      "|    reward             | -0.012270375 |\n",
      "|    std                | 15.4         |\n",
      "|    value_loss         | 0.000199     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 595           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.501         |\n",
      "|    reward             | -0.0026046738 |\n",
      "|    std                | 16.1          |\n",
      "|    value_loss         | 8.31e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 125\n",
      "day: 1112, episode: 125\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 781852.36\n",
      "total_reward: -218147.64\n",
      "total_cost: 88475.64\n",
      "total_trades: 7905\n",
      "Sharpe: -0.384\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 595          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -63.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -0.415       |\n",
      "|    reward             | -0.006766581 |\n",
      "|    std                | 16.8         |\n",
      "|    value_loss         | 0.000135     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 595          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.1        |\n",
      "|    explained_variance | -1.87        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.461        |\n",
      "|    reward             | -0.008191423 |\n",
      "|    std                | 17.6         |\n",
      "|    value_loss         | 5.66e-05     |\n",
      "----------------------------------------\n",
      "Episode: 126\n",
      "day: 1112, episode: 126\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 891429.29\n",
      "total_reward: -108570.71\n",
      "total_cost: 91482.71\n",
      "total_trades: 8478\n",
      "Sharpe: -0.134\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | -0.778       |\n",
      "|    reward             | -0.010176395 |\n",
      "|    std                | 18.4         |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.664        |\n",
      "|    reward             | -0.006073348 |\n",
      "|    std                | 19.3         |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.1       |\n",
      "|    explained_variance | 0.557       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.198       |\n",
      "|    reward             | -0.01639786 |\n",
      "|    std                | 20.2        |\n",
      "|    value_loss         | 1.2e-05     |\n",
      "---------------------------------------\n",
      "Episode: 127\n",
      "day: 1112, episode: 127\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 937288.85\n",
      "total_reward: -62711.15\n",
      "total_cost: 96779.15\n",
      "total_trades: 8532\n",
      "Sharpe: -0.070\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.8       |\n",
      "|    explained_variance | -0.487      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.237       |\n",
      "|    reward             | -0.03348151 |\n",
      "|    std                | 21.2        |\n",
      "|    value_loss         | 2.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.4        |\n",
      "|    explained_variance | 0.577        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | 0.893        |\n",
      "|    reward             | -0.014638423 |\n",
      "|    std                | 22.1         |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "Episode: 128\n",
      "day: 1112, episode: 128\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 743812.34\n",
      "total_reward: -256187.66\n",
      "total_cost: 96576.66\n",
      "total_trades: 8710\n",
      "Sharpe: -0.300\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.247        |\n",
      "|    reward             | -0.004247632 |\n",
      "|    std                | 22.8         |\n",
      "|    value_loss         | 2.87e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.757       |\n",
      "|    reward             | -0.01220109 |\n",
      "|    std                | 23.8        |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "Episode: 129\n",
      "day: 1112, episode: 129\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 931251.25\n",
      "total_reward: -68748.75\n",
      "total_cost: 101563.75\n",
      "total_trades: 8934\n",
      "Sharpe: -0.071\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 594           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -0.563        |\n",
      "|    reward             | -0.0060217837 |\n",
      "|    std                | 24.9          |\n",
      "|    value_loss         | 7.86e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.8        |\n",
      "|    explained_variance | -6.44        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -0.842       |\n",
      "|    reward             | -0.010722907 |\n",
      "|    std                | 26           |\n",
      "|    value_loss         | 0.000649     |\n",
      "----------------------------------------\n",
      "Episode: 130\n",
      "day: 1112, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 755343.85\n",
      "total_reward: -244656.15\n",
      "total_cost: 102691.15\n",
      "total_trades: 9154\n",
      "Sharpe: -0.369\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.764       |\n",
      "|    reward             | -0.009405897 |\n",
      "|    std                | 27           |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.9        |\n",
      "|    explained_variance | -23.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.365       |\n",
      "|    reward             | -0.012232501 |\n",
      "|    std                | 28           |\n",
      "|    value_loss         | 0.00082      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 594           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.4         |\n",
      "|    explained_variance | -0.066        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -3.43         |\n",
      "|    reward             | -0.0043923203 |\n",
      "|    std                | 28.9          |\n",
      "|    value_loss         | 0.00367       |\n",
      "-----------------------------------------\n",
      "Episode: 131\n",
      "day: 1112, episode: 131\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 915071.12\n",
      "total_reward: -84928.88\n",
      "total_cost: 108596.88\n",
      "total_trades: 9453\n",
      "Sharpe: -0.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 594           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 75            |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.328         |\n",
      "|    reward             | -0.0047113267 |\n",
      "|    std                | 30.1          |\n",
      "|    value_loss         | 2.22e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 0.615       |\n",
      "|    reward             | -0.06724196 |\n",
      "|    std                | 31.4        |\n",
      "|    value_loss         | 8.51e-05    |\n",
      "---------------------------------------\n",
      "Episode: 132\n",
      "day: 1112, episode: 132\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1134386.98\n",
      "total_reward: 134386.98\n",
      "total_cost: 122999.02\n",
      "total_trades: 9817\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 594           |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 77            |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9199          |\n",
      "|    policy_loss        | -0.0755       |\n",
      "|    reward             | -0.0048503666 |\n",
      "|    std                | 32.7          |\n",
      "|    value_loss         | 1.53e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.0532       |\n",
      "|    reward             | -0.014485387 |\n",
      "|    std                | 34.1         |\n",
      "|    value_loss         | 1.23e-05     |\n",
      "----------------------------------------\n",
      "Episode: 133\n",
      "day: 1112, episode: 133\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1150403.46\n",
      "total_reward: 150403.46\n",
      "total_cost: 119613.54\n",
      "total_trades: 10057\n",
      "Sharpe: 0.292\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 594           |\n",
      "|    iterations         | 9400          |\n",
      "|    time_elapsed       | 79            |\n",
      "|    total_timesteps    | 47000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.3         |\n",
      "|    explained_variance | -2.58         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9399          |\n",
      "|    policy_loss        | 0.578         |\n",
      "|    reward             | -0.0040882067 |\n",
      "|    std                | 35.4          |\n",
      "|    value_loss         | 9.69e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 0.00184      |\n",
      "|    reward             | -0.027064808 |\n",
      "|    std                | 36.7         |\n",
      "|    value_loss         | 8.48e-06     |\n",
      "----------------------------------------\n",
      "Episode: 134\n",
      "day: 1112, episode: 134\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1018407.97\n",
      "total_reward: 18407.97\n",
      "total_cost: 125697.03\n",
      "total_trades: 10209\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | -0.011767152 |\n",
      "|    std                | 38.2         |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.1        |\n",
      "|    explained_variance | -0.533       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.242       |\n",
      "|    reward             | -0.005147167 |\n",
      "|    std                | 39.9         |\n",
      "|    value_loss         | 3.35e-05     |\n",
      "----------------------------------------\n",
      "Episode: 135\n",
      "day: 1112, episode: 135\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1211271.48\n",
      "total_reward: 211271.48\n",
      "total_cost: 133875.52\n",
      "total_trades: 10729\n",
      "Sharpe: 0.369\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.332       |\n",
      "|    reward             | -0.012153052 |\n",
      "|    std                | 41.6         |\n",
      "|    value_loss         | 3.92e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.4        |\n",
      "|    explained_variance | -0.52        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | 0.616        |\n",
      "|    reward             | -0.004578599 |\n",
      "|    std                | 43.6         |\n",
      "|    value_loss         | 9.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 594          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.1        |\n",
      "|    explained_variance | -1.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.008037198 |\n",
      "|    std                | 45.7         |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trade",
   "id": "34703a104cb113b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:48:51.355812Z",
     "start_time": "2024-11-10T13:48:51.348973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "trade = trade.rename(columns={'time': 'date'})\n",
    "trade.head()\n",
    "env_kwargs = { \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 6.87e-5, \n",
    "    \"sell_cost_pct\": 1.0687e-3, \n",
    "    \"reward_scaling\": 1e-4, \n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1, \n",
    "    \"initial_buy\": False, \n",
    "    \"hundred_each_trade\": True \n",
    "} \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ],
   "id": "72f1db39b1ad7148",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:52:29.624937Z",
     "start_time": "2024-11-10T12:52:29.616729Z"
    }
   },
   "cell_type": "code",
   "source": "trade",
   "id": "90d45f3e82203800",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           tic        date  index     open     high      low    close  \\\n",
       "0    600000.SH  2019-08-01  16740    11.76    11.85    11.63    11.65   \n",
       "0    600009.SH  2019-08-01  16741    82.78    83.46    81.60    82.01   \n",
       "0    600016.SH  2019-08-01  16742     6.04     6.06     6.01     6.02   \n",
       "0    600028.SH  2019-08-01  16743     5.25     5.27     5.21     5.23   \n",
       "0    600030.SH  2019-08-01  16744    23.09    23.19    22.81    22.92   \n",
       "..         ...         ...    ...      ...      ...      ...      ...   \n",
       "103  600276.SH  2020-01-02  18295    88.00    88.10    86.85    87.68   \n",
       "103  600309.SH  2020-01-02  18296    56.50    57.60    55.69    55.89   \n",
       "103  600519.SH  2020-01-02  18297  1128.00  1145.06  1116.00  1130.00   \n",
       "103  600547.SH  2020-01-02  18298    32.31    32.96    32.26    32.90   \n",
       "103  600570.SH  2020-01-02  18299    78.81    79.98    77.96    79.44   \n",
       "\n",
       "     adjusted_close     volume      macd      boll_ub      boll_lb     rsi_30  \\\n",
       "0             11.65  324717.02  0.061723    11.954291    11.217709  51.629338   \n",
       "0             82.01   72583.66  1.456486    85.100887    78.654113  57.259597   \n",
       "0              6.02  517116.83 -0.045649     6.088116     5.935884  43.258474   \n",
       "0              5.23  616872.58 -0.030634     5.362514     5.179486  42.928615   \n",
       "0             22.92  809710.56  0.143135    23.703768    22.720232  51.752238   \n",
       "..              ...        ...       ...          ...          ...        ...   \n",
       "103           87.68  210809.91 -0.345742    87.726881    82.918119  53.727892   \n",
       "103           55.89  213379.65  1.824002    56.464963    49.288037  67.318349   \n",
       "103         1130.00  148099.16 -3.944016  1188.194602  1121.743398  46.814398   \n",
       "103           32.90  489106.37  0.348359    32.722690    30.612310  52.089075   \n",
       "103           79.44  175683.22  0.576198    81.327750    73.235250  54.957562   \n",
       "\n",
       "         cci_30      dx_30  close_30_sma  close_60_sma  \n",
       "0     30.105973   9.109642     11.632667     11.516667  \n",
       "0     28.697822  13.903367     81.707000     76.533333  \n",
       "0    -43.433030   5.774779      6.139667      6.162500  \n",
       "0    -77.147867  22.469955      5.324333      5.357333  \n",
       "0   -102.582689  11.905549     23.385667     21.918333  \n",
       "..          ...        ...           ...           ...  \n",
       "103   55.084385   2.193577     86.140333     87.454167  \n",
       "103  154.362552  50.898752     51.418667     48.306667  \n",
       "103  -98.839848  24.496850   1158.660667   1175.338000  \n",
       "103  155.084385  32.165604     31.288667     31.498333  \n",
       "103   97.011383  16.335704     76.178000     76.136500  \n",
       "\n",
       "[1560 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16740</td>\n",
       "      <td>11.76</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.65</td>\n",
       "      <td>324717.02</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>11.954291</td>\n",
       "      <td>11.217709</td>\n",
       "      <td>51.629338</td>\n",
       "      <td>30.105973</td>\n",
       "      <td>9.109642</td>\n",
       "      <td>11.632667</td>\n",
       "      <td>11.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16741</td>\n",
       "      <td>82.78</td>\n",
       "      <td>83.46</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.01</td>\n",
       "      <td>82.01</td>\n",
       "      <td>72583.66</td>\n",
       "      <td>1.456486</td>\n",
       "      <td>85.100887</td>\n",
       "      <td>78.654113</td>\n",
       "      <td>57.259597</td>\n",
       "      <td>28.697822</td>\n",
       "      <td>13.903367</td>\n",
       "      <td>81.707000</td>\n",
       "      <td>76.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16742</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>517116.83</td>\n",
       "      <td>-0.045649</td>\n",
       "      <td>6.088116</td>\n",
       "      <td>5.935884</td>\n",
       "      <td>43.258474</td>\n",
       "      <td>-43.433030</td>\n",
       "      <td>5.774779</td>\n",
       "      <td>6.139667</td>\n",
       "      <td>6.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16743</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.23</td>\n",
       "      <td>616872.58</td>\n",
       "      <td>-0.030634</td>\n",
       "      <td>5.362514</td>\n",
       "      <td>5.179486</td>\n",
       "      <td>42.928615</td>\n",
       "      <td>-77.147867</td>\n",
       "      <td>22.469955</td>\n",
       "      <td>5.324333</td>\n",
       "      <td>5.357333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16744</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.19</td>\n",
       "      <td>22.81</td>\n",
       "      <td>22.92</td>\n",
       "      <td>22.92</td>\n",
       "      <td>809710.56</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>23.703768</td>\n",
       "      <td>22.720232</td>\n",
       "      <td>51.752238</td>\n",
       "      <td>-102.582689</td>\n",
       "      <td>11.905549</td>\n",
       "      <td>23.385667</td>\n",
       "      <td>21.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18295</td>\n",
       "      <td>88.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>86.85</td>\n",
       "      <td>87.68</td>\n",
       "      <td>87.68</td>\n",
       "      <td>210809.91</td>\n",
       "      <td>-0.345742</td>\n",
       "      <td>87.726881</td>\n",
       "      <td>82.918119</td>\n",
       "      <td>53.727892</td>\n",
       "      <td>55.084385</td>\n",
       "      <td>2.193577</td>\n",
       "      <td>86.140333</td>\n",
       "      <td>87.454167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18296</td>\n",
       "      <td>56.50</td>\n",
       "      <td>57.60</td>\n",
       "      <td>55.69</td>\n",
       "      <td>55.89</td>\n",
       "      <td>55.89</td>\n",
       "      <td>213379.65</td>\n",
       "      <td>1.824002</td>\n",
       "      <td>56.464963</td>\n",
       "      <td>49.288037</td>\n",
       "      <td>67.318349</td>\n",
       "      <td>154.362552</td>\n",
       "      <td>50.898752</td>\n",
       "      <td>51.418667</td>\n",
       "      <td>48.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18297</td>\n",
       "      <td>1128.00</td>\n",
       "      <td>1145.06</td>\n",
       "      <td>1116.00</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>148099.16</td>\n",
       "      <td>-3.944016</td>\n",
       "      <td>1188.194602</td>\n",
       "      <td>1121.743398</td>\n",
       "      <td>46.814398</td>\n",
       "      <td>-98.839848</td>\n",
       "      <td>24.496850</td>\n",
       "      <td>1158.660667</td>\n",
       "      <td>1175.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600547.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18298</td>\n",
       "      <td>32.31</td>\n",
       "      <td>32.96</td>\n",
       "      <td>32.26</td>\n",
       "      <td>32.90</td>\n",
       "      <td>32.90</td>\n",
       "      <td>489106.37</td>\n",
       "      <td>0.348359</td>\n",
       "      <td>32.722690</td>\n",
       "      <td>30.612310</td>\n",
       "      <td>52.089075</td>\n",
       "      <td>155.084385</td>\n",
       "      <td>32.165604</td>\n",
       "      <td>31.288667</td>\n",
       "      <td>31.498333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18299</td>\n",
       "      <td>78.81</td>\n",
       "      <td>79.98</td>\n",
       "      <td>77.96</td>\n",
       "      <td>79.44</td>\n",
       "      <td>79.44</td>\n",
       "      <td>175683.22</td>\n",
       "      <td>0.576198</td>\n",
       "      <td>81.327750</td>\n",
       "      <td>73.235250</td>\n",
       "      <td>54.957562</td>\n",
       "      <td>97.011383</td>\n",
       "      <td>16.335704</td>\n",
       "      <td>76.178000</td>\n",
       "      <td>76.136500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:50:36.831930Z",
     "start_time": "2024-11-10T13:50:36.818648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import DDPG\n",
    "\n",
    "trained_model = DDPG.load(TRAIN_START_DATE+'/ashare_trained_models_ddpg')"
   ],
   "id": "d46f1c97cb057e79",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:50:40.706465Z",
     "start_time": "2024-11-10T13:50:40.636167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_model, environment=e_trade_gym)\n",
    "df_account_value\n",
    "# df_actions"
   ],
   "id": "52736fba3f68f593",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 103, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1095681.31\n",
      "total_reward: 95681.31\n",
      "total_cost: 68.69\n",
      "total_trades: 63\n",
      "Sharpe: 1.439\n",
      "=================================\n",
      "hit end!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          date  account_value\n",
       "0   2019-08-01   9.999955e+05\n",
       "1   2019-08-02   9.974511e+05\n",
       "2   2019-08-05   9.943469e+05\n",
       "3   2019-08-06   9.938627e+05\n",
       "4   2019-08-07   9.912585e+05\n",
       "..         ...            ...\n",
       "98  2019-12-25   1.050891e+06\n",
       "99  2019-12-26   1.063477e+06\n",
       "100 2019-12-27   1.056715e+06\n",
       "101 2019-12-30   1.094123e+06\n",
       "102 2019-12-31   1.095681e+06\n",
       "\n",
       "[103 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>9.999955e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>9.974511e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>9.943469e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>9.938627e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>9.912585e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>1.050891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>1.063477e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>1.056715e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1.094123e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1.095681e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:50:46.948936Z",
     "start_time": "2024-11-10T13:50:46.937539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_actions.to_csv(\"ddpg_action.csv\", index=False)\n",
    "df_actions"
   ],
   "id": "3b48fd5ef81069dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01       1000          0          0       1000       1000          0   \n",
       "2019-08-01       1000          0          0       1000       1000          0   \n",
       "2019-08-02       1000          0          0       1000       1000          0   \n",
       "2019-08-05       1000          0          0       1000       1000          0   \n",
       "2019-08-06       1000          0          0       1000       1000          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-24          0          0          0          0          0          0   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "\n",
       "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01          0          0          0       1000          0          0   \n",
       "2019-08-01          0          0          0       1000          0          0   \n",
       "2019-08-02          0          0          0       1000          0          0   \n",
       "2019-08-05          0          0          0       1000          0          0   \n",
       "2019-08-06          0          0          0       1000          0          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-24          0          0          0          0          0          0   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "\n",
       "            600519.SH  600547.SH  600570.SH  \n",
       "date                                         \n",
       "2019-08-01          0          0          0  \n",
       "2019-08-01          0          0          0  \n",
       "2019-08-02          0          0          0  \n",
       "2019-08-05          0          0          0  \n",
       "2019-08-06          0          0          0  \n",
       "...               ...        ...        ...  \n",
       "2019-12-24          0          0          0  \n",
       "2019-12-25          0          0          0  \n",
       "2019-12-26          0          0          0  \n",
       "2019-12-27          0          0          0  \n",
       "2019-12-30          0          0          0  \n",
       "\n",
       "[103 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>600000.SH</th>\n",
       "      <th>600009.SH</th>\n",
       "      <th>600016.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600050.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600547.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backtest",
   "id": "2d657a88f953cb4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### matplotlib inline",
   "id": "245030c28cf3d70f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:52:29.706088Z",
     "start_time": "2024-11-10T12:52:29.697284Z"
    }
   },
   "cell_type": "code",
   "source": "trade",
   "id": "b42eb7edf514fa60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           tic        date  index     open     high      low    close  \\\n",
       "0    600000.SH  2019-08-01  16740    11.76    11.85    11.63    11.65   \n",
       "0    600009.SH  2019-08-01  16741    82.78    83.46    81.60    82.01   \n",
       "0    600016.SH  2019-08-01  16742     6.04     6.06     6.01     6.02   \n",
       "0    600028.SH  2019-08-01  16743     5.25     5.27     5.21     5.23   \n",
       "0    600030.SH  2019-08-01  16744    23.09    23.19    22.81    22.92   \n",
       "..         ...         ...    ...      ...      ...      ...      ...   \n",
       "103  600276.SH  2020-01-02  18295    88.00    88.10    86.85    87.68   \n",
       "103  600309.SH  2020-01-02  18296    56.50    57.60    55.69    55.89   \n",
       "103  600519.SH  2020-01-02  18297  1128.00  1145.06  1116.00  1130.00   \n",
       "103  600547.SH  2020-01-02  18298    32.31    32.96    32.26    32.90   \n",
       "103  600570.SH  2020-01-02  18299    78.81    79.98    77.96    79.44   \n",
       "\n",
       "     adjusted_close     volume      macd      boll_ub      boll_lb     rsi_30  \\\n",
       "0             11.65  324717.02  0.061723    11.954291    11.217709  51.629338   \n",
       "0             82.01   72583.66  1.456486    85.100887    78.654113  57.259597   \n",
       "0              6.02  517116.83 -0.045649     6.088116     5.935884  43.258474   \n",
       "0              5.23  616872.58 -0.030634     5.362514     5.179486  42.928615   \n",
       "0             22.92  809710.56  0.143135    23.703768    22.720232  51.752238   \n",
       "..              ...        ...       ...          ...          ...        ...   \n",
       "103           87.68  210809.91 -0.345742    87.726881    82.918119  53.727892   \n",
       "103           55.89  213379.65  1.824002    56.464963    49.288037  67.318349   \n",
       "103         1130.00  148099.16 -3.944016  1188.194602  1121.743398  46.814398   \n",
       "103           32.90  489106.37  0.348359    32.722690    30.612310  52.089075   \n",
       "103           79.44  175683.22  0.576198    81.327750    73.235250  54.957562   \n",
       "\n",
       "         cci_30      dx_30  close_30_sma  close_60_sma  \n",
       "0     30.105973   9.109642     11.632667     11.516667  \n",
       "0     28.697822  13.903367     81.707000     76.533333  \n",
       "0    -43.433030   5.774779      6.139667      6.162500  \n",
       "0    -77.147867  22.469955      5.324333      5.357333  \n",
       "0   -102.582689  11.905549     23.385667     21.918333  \n",
       "..          ...        ...           ...           ...  \n",
       "103   55.084385   2.193577     86.140333     87.454167  \n",
       "103  154.362552  50.898752     51.418667     48.306667  \n",
       "103  -98.839848  24.496850   1158.660667   1175.338000  \n",
       "103  155.084385  32.165604     31.288667     31.498333  \n",
       "103   97.011383  16.335704     76.178000     76.136500  \n",
       "\n",
       "[1560 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16740</td>\n",
       "      <td>11.76</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.65</td>\n",
       "      <td>324717.02</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>11.954291</td>\n",
       "      <td>11.217709</td>\n",
       "      <td>51.629338</td>\n",
       "      <td>30.105973</td>\n",
       "      <td>9.109642</td>\n",
       "      <td>11.632667</td>\n",
       "      <td>11.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16741</td>\n",
       "      <td>82.78</td>\n",
       "      <td>83.46</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.01</td>\n",
       "      <td>82.01</td>\n",
       "      <td>72583.66</td>\n",
       "      <td>1.456486</td>\n",
       "      <td>85.100887</td>\n",
       "      <td>78.654113</td>\n",
       "      <td>57.259597</td>\n",
       "      <td>28.697822</td>\n",
       "      <td>13.903367</td>\n",
       "      <td>81.707000</td>\n",
       "      <td>76.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16742</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>517116.83</td>\n",
       "      <td>-0.045649</td>\n",
       "      <td>6.088116</td>\n",
       "      <td>5.935884</td>\n",
       "      <td>43.258474</td>\n",
       "      <td>-43.433030</td>\n",
       "      <td>5.774779</td>\n",
       "      <td>6.139667</td>\n",
       "      <td>6.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16743</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.23</td>\n",
       "      <td>616872.58</td>\n",
       "      <td>-0.030634</td>\n",
       "      <td>5.362514</td>\n",
       "      <td>5.179486</td>\n",
       "      <td>42.928615</td>\n",
       "      <td>-77.147867</td>\n",
       "      <td>22.469955</td>\n",
       "      <td>5.324333</td>\n",
       "      <td>5.357333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16744</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.19</td>\n",
       "      <td>22.81</td>\n",
       "      <td>22.92</td>\n",
       "      <td>22.92</td>\n",
       "      <td>809710.56</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>23.703768</td>\n",
       "      <td>22.720232</td>\n",
       "      <td>51.752238</td>\n",
       "      <td>-102.582689</td>\n",
       "      <td>11.905549</td>\n",
       "      <td>23.385667</td>\n",
       "      <td>21.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18295</td>\n",
       "      <td>88.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>86.85</td>\n",
       "      <td>87.68</td>\n",
       "      <td>87.68</td>\n",
       "      <td>210809.91</td>\n",
       "      <td>-0.345742</td>\n",
       "      <td>87.726881</td>\n",
       "      <td>82.918119</td>\n",
       "      <td>53.727892</td>\n",
       "      <td>55.084385</td>\n",
       "      <td>2.193577</td>\n",
       "      <td>86.140333</td>\n",
       "      <td>87.454167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18296</td>\n",
       "      <td>56.50</td>\n",
       "      <td>57.60</td>\n",
       "      <td>55.69</td>\n",
       "      <td>55.89</td>\n",
       "      <td>55.89</td>\n",
       "      <td>213379.65</td>\n",
       "      <td>1.824002</td>\n",
       "      <td>56.464963</td>\n",
       "      <td>49.288037</td>\n",
       "      <td>67.318349</td>\n",
       "      <td>154.362552</td>\n",
       "      <td>50.898752</td>\n",
       "      <td>51.418667</td>\n",
       "      <td>48.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18297</td>\n",
       "      <td>1128.00</td>\n",
       "      <td>1145.06</td>\n",
       "      <td>1116.00</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>148099.16</td>\n",
       "      <td>-3.944016</td>\n",
       "      <td>1188.194602</td>\n",
       "      <td>1121.743398</td>\n",
       "      <td>46.814398</td>\n",
       "      <td>-98.839848</td>\n",
       "      <td>24.496850</td>\n",
       "      <td>1158.660667</td>\n",
       "      <td>1175.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600547.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18298</td>\n",
       "      <td>32.31</td>\n",
       "      <td>32.96</td>\n",
       "      <td>32.26</td>\n",
       "      <td>32.90</td>\n",
       "      <td>32.90</td>\n",
       "      <td>489106.37</td>\n",
       "      <td>0.348359</td>\n",
       "      <td>32.722690</td>\n",
       "      <td>30.612310</td>\n",
       "      <td>52.089075</td>\n",
       "      <td>155.084385</td>\n",
       "      <td>32.165604</td>\n",
       "      <td>31.288667</td>\n",
       "      <td>31.498333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>18299</td>\n",
       "      <td>78.81</td>\n",
       "      <td>79.98</td>\n",
       "      <td>77.96</td>\n",
       "      <td>79.44</td>\n",
       "      <td>79.44</td>\n",
       "      <td>175683.22</td>\n",
       "      <td>0.576198</td>\n",
       "      <td>81.327750</td>\n",
       "      <td>73.235250</td>\n",
       "      <td>54.957562</td>\n",
       "      <td>97.011383</td>\n",
       "      <td>16.335704</td>\n",
       "      <td>76.178000</td>\n",
       "      <td>76.136500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:53:19.389187Z",
     "start_time": "2024-11-10T13:53:19.377319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_account_value = df_account_value.rename(columns={'date': 'time'})\n",
    "\n",
    "trade = trade.rename(columns={'date': 'time'})\n",
    "plot_end_date = '2019-12-31'\n",
    "trade_plot = trade[trade['time'] <= plot_end_date]\n",
    "trade_plot\n"
   ],
   "id": "7a084fc9952e03d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           tic        time  index     open     high      low    close  \\\n",
       "0    600000.SH  2019-08-01  16740    11.76    11.85    11.63    11.65   \n",
       "0    600009.SH  2019-08-01  16741    82.78    83.46    81.60    82.01   \n",
       "0    600016.SH  2019-08-01  16742     6.04     6.06     6.01     6.02   \n",
       "0    600028.SH  2019-08-01  16743     5.25     5.27     5.21     5.23   \n",
       "0    600030.SH  2019-08-01  16744    23.09    23.19    22.81    22.92   \n",
       "..         ...         ...    ...      ...      ...      ...      ...   \n",
       "102  600276.SH  2019-12-31  18280    85.27    88.18    85.27    87.52   \n",
       "102  600309.SH  2019-12-31  18281    56.00    57.19    55.68    56.17   \n",
       "102  600519.SH  2019-12-31  18282  1183.00  1188.00  1176.51  1183.00   \n",
       "102  600547.SH  2019-12-31  18283    32.44    32.79    32.22    32.62   \n",
       "102  600570.SH  2019-12-31  18284    77.42    77.84    76.55    77.73   \n",
       "\n",
       "     adjusted_close     volume      macd      boll_ub      boll_lb     rsi_30  \\\n",
       "0             11.65  324717.02  0.061723    11.954291    11.217709  51.629338   \n",
       "0             82.01   72583.66  1.456486    85.100887    78.654113  57.259597   \n",
       "0              6.02  517116.83 -0.045649     6.088116     5.935884  43.258474   \n",
       "0              5.23  616872.58 -0.030634     5.362514     5.179486  42.928615   \n",
       "0             22.92  809710.56  0.143135    23.703768    22.720232  51.752238   \n",
       "..              ...        ...       ...          ...          ...        ...   \n",
       "102           87.52  220793.14 -0.573297    87.363472    83.078528  53.502459   \n",
       "102           56.17  142068.42  1.780555    56.261337    48.778663  68.325632   \n",
       "102         1183.00   22588.81 -1.622947  1189.173694  1119.997306  53.683567   \n",
       "102           32.62  422904.08  0.286032    32.557092    30.709908  51.090729   \n",
       "102           77.73  116145.80  0.429811    81.480465    72.325535  52.555614   \n",
       "\n",
       "         cci_30      dx_30  close_30_sma  close_60_sma  \n",
       "0     30.105973   9.109642     11.632667     11.516667  \n",
       "0     28.697822  13.903367     81.707000     76.533333  \n",
       "0    -43.433030   5.774779      6.139667      6.162500  \n",
       "0    -77.147867  22.469955      5.324333      5.357333  \n",
       "0   -102.582689  11.905549     23.385667     21.918333  \n",
       "..          ...        ...           ...           ...  \n",
       "102   20.134853   2.193577     86.384333     87.304333  \n",
       "102  161.334644  48.804471     51.089000     48.101667  \n",
       "102   62.426718   3.403761   1162.119000   1175.618167  \n",
       "102  150.027238  29.847459     31.208333     31.537833  \n",
       "102   41.823963   3.228778     76.106667     76.047500  \n",
       "\n",
       "[1545 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16740</td>\n",
       "      <td>11.76</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.65</td>\n",
       "      <td>324717.02</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>11.954291</td>\n",
       "      <td>11.217709</td>\n",
       "      <td>51.629338</td>\n",
       "      <td>30.105973</td>\n",
       "      <td>9.109642</td>\n",
       "      <td>11.632667</td>\n",
       "      <td>11.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16741</td>\n",
       "      <td>82.78</td>\n",
       "      <td>83.46</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.01</td>\n",
       "      <td>82.01</td>\n",
       "      <td>72583.66</td>\n",
       "      <td>1.456486</td>\n",
       "      <td>85.100887</td>\n",
       "      <td>78.654113</td>\n",
       "      <td>57.259597</td>\n",
       "      <td>28.697822</td>\n",
       "      <td>13.903367</td>\n",
       "      <td>81.707000</td>\n",
       "      <td>76.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16742</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>517116.83</td>\n",
       "      <td>-0.045649</td>\n",
       "      <td>6.088116</td>\n",
       "      <td>5.935884</td>\n",
       "      <td>43.258474</td>\n",
       "      <td>-43.433030</td>\n",
       "      <td>5.774779</td>\n",
       "      <td>6.139667</td>\n",
       "      <td>6.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16743</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.23</td>\n",
       "      <td>616872.58</td>\n",
       "      <td>-0.030634</td>\n",
       "      <td>5.362514</td>\n",
       "      <td>5.179486</td>\n",
       "      <td>42.928615</td>\n",
       "      <td>-77.147867</td>\n",
       "      <td>22.469955</td>\n",
       "      <td>5.324333</td>\n",
       "      <td>5.357333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>16744</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.19</td>\n",
       "      <td>22.81</td>\n",
       "      <td>22.92</td>\n",
       "      <td>22.92</td>\n",
       "      <td>809710.56</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>23.703768</td>\n",
       "      <td>22.720232</td>\n",
       "      <td>51.752238</td>\n",
       "      <td>-102.582689</td>\n",
       "      <td>11.905549</td>\n",
       "      <td>23.385667</td>\n",
       "      <td>21.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>18280</td>\n",
       "      <td>85.27</td>\n",
       "      <td>88.18</td>\n",
       "      <td>85.27</td>\n",
       "      <td>87.52</td>\n",
       "      <td>87.52</td>\n",
       "      <td>220793.14</td>\n",
       "      <td>-0.573297</td>\n",
       "      <td>87.363472</td>\n",
       "      <td>83.078528</td>\n",
       "      <td>53.502459</td>\n",
       "      <td>20.134853</td>\n",
       "      <td>2.193577</td>\n",
       "      <td>86.384333</td>\n",
       "      <td>87.304333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>18281</td>\n",
       "      <td>56.00</td>\n",
       "      <td>57.19</td>\n",
       "      <td>55.68</td>\n",
       "      <td>56.17</td>\n",
       "      <td>56.17</td>\n",
       "      <td>142068.42</td>\n",
       "      <td>1.780555</td>\n",
       "      <td>56.261337</td>\n",
       "      <td>48.778663</td>\n",
       "      <td>68.325632</td>\n",
       "      <td>161.334644</td>\n",
       "      <td>48.804471</td>\n",
       "      <td>51.089000</td>\n",
       "      <td>48.101667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>18282</td>\n",
       "      <td>1183.00</td>\n",
       "      <td>1188.00</td>\n",
       "      <td>1176.51</td>\n",
       "      <td>1183.00</td>\n",
       "      <td>1183.00</td>\n",
       "      <td>22588.81</td>\n",
       "      <td>-1.622947</td>\n",
       "      <td>1189.173694</td>\n",
       "      <td>1119.997306</td>\n",
       "      <td>53.683567</td>\n",
       "      <td>62.426718</td>\n",
       "      <td>3.403761</td>\n",
       "      <td>1162.119000</td>\n",
       "      <td>1175.618167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>600547.SH</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>18283</td>\n",
       "      <td>32.44</td>\n",
       "      <td>32.79</td>\n",
       "      <td>32.22</td>\n",
       "      <td>32.62</td>\n",
       "      <td>32.62</td>\n",
       "      <td>422904.08</td>\n",
       "      <td>0.286032</td>\n",
       "      <td>32.557092</td>\n",
       "      <td>30.709908</td>\n",
       "      <td>51.090729</td>\n",
       "      <td>150.027238</td>\n",
       "      <td>29.847459</td>\n",
       "      <td>31.208333</td>\n",
       "      <td>31.537833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>18284</td>\n",
       "      <td>77.42</td>\n",
       "      <td>77.84</td>\n",
       "      <td>76.55</td>\n",
       "      <td>77.73</td>\n",
       "      <td>77.73</td>\n",
       "      <td>116145.80</td>\n",
       "      <td>0.429811</td>\n",
       "      <td>81.480465</td>\n",
       "      <td>72.325535</td>\n",
       "      <td>52.555614</td>\n",
       "      <td>41.823963</td>\n",
       "      <td>3.228778</td>\n",
       "      <td>76.106667</td>\n",
       "      <td>76.047500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:53:23.620579Z",
     "start_time": "2024-11-10T13:53:23.488566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plotter = ReturnPlotter(df_account_value, trade_plot, TRADE_START_DATE, plot_end_date)\n",
    "plotter.plot()"
   ],
   "id": "29d2a937d5e2e9a",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Error: ValueError: x and y must have same first dimension, but have shapes (103,) and (104,)**\n",
    "\n",
    "https://github.com/AI4Finance-Foundation/FinRL-Tutorials/issues/91\n",
    "\n",
    "df_account_value 知道2019-12-31，而time_series却到了2020-01-02， 所以plot中传入的end_date需要变成2020-01-01，同时需要移除trade中2020-01-02的数据"
   ],
   "id": "d0eefc2c26c2fec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:56:32.978523Z",
     "start_time": "2024-11-10T13:56:32.872409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ticket: SSE 50：000016\n",
    "plotter.plot(\"000016\")"
   ],
   "id": "7969ba10d3265c7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "获取失败，请检查网络.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ticket: SSE 50：000016\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mplotter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m000016\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction/FinRL-Meta/meta/data_processors/tushare.py:195\u001B[0m, in \u001B[0;36mReturnPlotter.plot\u001B[0;34m(self, baseline_ticket)\u001B[0m\n\u001B[1;32m    192\u001B[0m tic2label \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m399300\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCSI 300 Index\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m000016\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSSE 50 Index\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m baseline_ticket:\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# 使用指定ticket作为baseline\u001B[39;00m\n\u001B[0;32m--> 195\u001B[0m     baseline_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_baseline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbaseline_ticket\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m     baseline_date_list \u001B[38;5;241m=\u001B[39m baseline_df\u001B[38;5;241m.\u001B[39mtime\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    197\u001B[0m     df_date_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf_account_value\u001B[38;5;241m.\u001B[39mtime\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m~/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction/FinRL-Meta/meta/data_processors/tushare.py:178\u001B[0m, in \u001B[0;36mReturnPlotter.get_baseline\u001B[0;34m(self, ticket)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_baseline\u001B[39m(\u001B[38;5;28mself\u001B[39m, ticket):\n\u001B[0;32m--> 178\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_hist_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mticket\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     df\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdt\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m    180\u001B[0m     df\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df))\n",
      "File \u001B[0;32m~/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages/tushare/stock/trading.py:104\u001B[0m, in \u001B[0;36mget_hist_data\u001B[0;34m(code, start, end, ktype, retry_count, pause)\u001B[0m\n\u001B[1;32m    102\u001B[0m         df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msort_index(ascending \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m--> 104\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(ct\u001B[38;5;241m.\u001B[39mNETWORK_URL_ERROR_MSG)\n",
      "\u001B[0;31mOSError\u001B[0m: 获取失败，请检查网络."
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CSI 300",
   "id": "d931cfb1ff14ac6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:04:52.739033Z",
     "start_time": "2024-11-10T14:04:52.373509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_df = plotter.get_baseline('399300')\n",
    "baseline_df"
   ],
   "id": "4d337110434880ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "获取失败，请检查网络.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m baseline_df \u001B[38;5;241m=\u001B[39m \u001B[43mplotter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_baseline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m399300\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m baseline_df\n",
      "File \u001B[0;32m~/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/1-Introduction/FinRL-Meta/meta/data_processors/tushare.py:178\u001B[0m, in \u001B[0;36mReturnPlotter.get_baseline\u001B[0;34m(self, ticket)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_baseline\u001B[39m(\u001B[38;5;28mself\u001B[39m, ticket):\n\u001B[0;32m--> 178\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_hist_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mticket\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     df\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdt\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m    180\u001B[0m     df\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df))\n",
      "File \u001B[0;32m~/Documents/ProgramingGuide/SourceCode/GithubRepo/everyfine/FinRLLearn/FinRL-Tutorials-Learn/.venv/lib/python3.10/site-packages/tushare/stock/trading.py:104\u001B[0m, in \u001B[0;36mget_hist_data\u001B[0;34m(code, start, end, ktype, retry_count, pause)\u001B[0m\n\u001B[1;32m    102\u001B[0m         df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msort_index(ascending \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m--> 104\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(ct\u001B[38;5;241m.\u001B[39mNETWORK_URL_ERROR_MSG)\n",
      "\u001B[0;31mOSError\u001B[0m: 获取失败，请检查网络."
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:05:46.087827Z",
     "start_time": "2024-11-10T14:05:46.080741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return"
   ],
   "id": "f540d6a6f39bd448",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2019-08-01 00:00:00+00:00         NaN\n",
       "2019-08-02 00:00:00+00:00   -0.002544\n",
       "2019-08-05 00:00:00+00:00   -0.003112\n",
       "2019-08-06 00:00:00+00:00   -0.000487\n",
       "2019-08-07 00:00:00+00:00   -0.002620\n",
       "                               ...   \n",
       "2019-12-25 00:00:00+00:00   -0.005259\n",
       "2019-12-26 00:00:00+00:00    0.011977\n",
       "2019-12-27 00:00:00+00:00   -0.006358\n",
       "2019-12-30 00:00:00+00:00    0.035400\n",
       "2019-12-31 00:00:00+00:00    0.001424\n",
       "Name: daily_return, Length: 103, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:06:38.210481Z",
     "start_time": "2024-11-10T14:06:38.195845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "daily_return_base"
   ],
   "id": "e7b9d182ab7b3804",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[79], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m daily_return_base \u001B[38;5;241m=\u001B[39m plotter\u001B[38;5;241m.\u001B[39mget_return(\u001B[43mbaseline_df\u001B[49m, value_col_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m daily_return_base\n",
      "\u001B[0;31mNameError\u001B[0m: name 'baseline_df' is not defined"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:08:13.704206Z",
     "start_time": "2024-11-10T14:08:13.694052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ],
   "id": "e9fb986af197c29a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "perf_stats_all: Annual return          0.250536\n",
      "Cumulative returns     0.095686\n",
      "Annual volatility      0.166416\n",
      "Sharpe ratio           1.439246\n",
      "Calmar ratio           2.616460\n",
      "Stability              0.005206\n",
      "Max drawdown          -0.095754\n",
      "Omega ratio            1.272748\n",
      "Sortino ratio          2.399210\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.281685\n",
      "Daily value at risk   -0.020016\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
